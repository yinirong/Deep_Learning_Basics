{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CarNet\n",
    "\n",
    "Welcome to the final assignment in this course. It's been a long journey, but you are now ready to unleash the powers of neural networks at any task. In this assignment, we will be working with a collection of photos related to driving vehicles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import json\n",
    "sns.set_context('talk')\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Download Data\n",
    "\n",
    "The dataset consists of 2 segments: \n",
    "* train: the metadata file contains the file names and the count of different objects in each image.\n",
    "* score: the metadata file contains the file names of images to be used for the final predictions.\n",
    "\n",
    "Target variables (in this order):\n",
    "1. signal\n",
    "2. vehicle\n",
    "\n",
    "These target variables are defined as follows:\n",
    "* signal =  traffic light + stop sign\n",
    "* vehicle = car + bus + truck + train + motorcycle + bicycle + airplane + boat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !aws s3 cp s3://danylo-ucla/carnet_dataset.zip ./\n",
    "# !unzip -u -q carnet_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car</th>\n",
       "      <th>bus</th>\n",
       "      <th>truck</th>\n",
       "      <th>train</th>\n",
       "      <th>motorcycle</th>\n",
       "      <th>bicycle</th>\n",
       "      <th>airplane</th>\n",
       "      <th>boat</th>\n",
       "      <th>traffic light</th>\n",
       "      <th>stop sign</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>signal</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>000000000064.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>000000000073.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>000000000074.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>000000000081.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>000000000086.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   car  bus  truck  train  motorcycle  bicycle  airplane  boat  traffic light  \\\n",
       "0  1.0  0.0    1.0    0.0         0.0      0.0       0.0   0.0            0.0   \n",
       "1  0.0  0.0    0.0    0.0         2.0      0.0       0.0   0.0            0.0   \n",
       "2  0.0  0.0    0.0    0.0         0.0      1.0       0.0   0.0            0.0   \n",
       "3  0.0  0.0    0.0    0.0         0.0      0.0       1.0   0.0            0.0   \n",
       "4  0.0  0.0    0.0    0.0         1.0      0.0       0.0   0.0            0.0   \n",
       "\n",
       "   stop sign  vehicle  signal         file_name  \n",
       "0        1.0      2.0     1.0  000000000064.jpg  \n",
       "1        0.0      2.0     0.0  000000000073.jpg  \n",
       "2        0.0      1.0     0.0  000000000074.jpg  \n",
       "3        0.0      1.0     0.0  000000000081.jpg  \n",
       "4        0.0      1.0     0.0  000000000086.jpg  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metadata = pd.read_csv('carnet_dataset/train/metadata.csv')\n",
    "train_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000000071.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000000149.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000000260.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000000307.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000000690.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          file_name\n",
       "0  000000000071.jpg\n",
       "1  000000000149.jpg\n",
       "2  000000000260.jpg\n",
       "3  000000000307.jpg\n",
       "4  000000000690.jpg"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score metadata defines the expected order of the photos in the submitted predictions file.\n",
    "\n",
    "score_metadata = pd.read_csv('carnet_dataset/score/metadata.csv')\n",
    "score_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23228, 13)\n",
      "(5766, 1)\n"
     ]
    }
   ],
   "source": [
    "# Data size\n",
    "\n",
    "print(train_metadata.shape)\n",
    "print(score_metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display random image\n",
    "# random.seed(43)\n",
    "\n",
    "# i = random.randint(0, train_metadata.shape[0])\n",
    "\n",
    "# file_name = train_metadata['file_name'].iloc[i]\n",
    "# vehicles = train_metadata['vehicle'].iloc[i]\n",
    "# signals = train_metadata['signal'].iloc[i] \n",
    "\n",
    "# plt.title(f'Vehicles: {vehicles}, Signals: {signals}')\n",
    "# plt.imshow(Image.open(f'carnet_dataset/train/images/{file_name}'))\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Object Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['detector_result_train_merged.json', 'detector_result_train_extra.json']\n",
    "file_jsons = None\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_json = json.load(file)\n",
    "        if file_jsons == None:\n",
    "            file_jsons = file_json\n",
    "        else:\n",
    "            file_jsons.update(file_json)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', '1', '2', '3', '4', '5', '6'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_jsons.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specifying the file path to save the JSON file\n",
    "# file_path = 'detector_result_train1.json'\n",
    "file_path = 'detector_result_train_extra_merged.json'\n",
    "\n",
    "# Saving the dictionary to a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(file_jsons, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = 'detector_result_train_merged.json'\n",
    "file_path = 'detector_result_train_extra_merged.json'\n",
    "file_jsons = None\n",
    "with open(file_path, 'r') as file:\n",
    "    file_jsons = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Heuristic Approach using 7 Object Detection Models\n",
    "\n",
    "Looping through confidence score threshold from 20% to 50% using either the maximum or the mode predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_images = 3000\n",
    "detector_outputs = []\n",
    "for i in range(0, num_images):\n",
    "    outputs = []\n",
    "    for j in range(0, len(file_jsons)):\n",
    "        detection_classes = tf.convert_to_tensor(np.array(file_jsons[str(j)][str(i)]['detection_classes']['value']))\n",
    "        detection_scores = tf.convert_to_tensor(np.array(file_jsons[str(j)][str(i)]['detection_scores']['value']))\n",
    "        outputs.append((detection_classes, detection_scores))\n",
    "    detector_outputs.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(detector_outputs))  # number of images\n",
    "print(len(detector_outputs[0]))  # number of detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from utils.mscoco import load_class_map\n",
    "\n",
    "\n",
    "def get_counts(threshold):\n",
    "    class_map = load_class_map()\n",
    "    num_images = 3000\n",
    "    signals = ['traffic light', 'stop sign']\n",
    "    vehicles = ['car', 'bus', 'truck', 'train', 'motorcycle', 'bicycle', 'airplane', 'boat']\n",
    "    train_pred_max = []\n",
    "    train_pred_mode = []\n",
    "\n",
    "    for i in range(0, num_images):\n",
    "        model_outputs = detector_outputs[i]\n",
    "        image_pred = []\n",
    "\n",
    "        for j in range(0, 7):\n",
    "            detection_classes, detection_scores = model_outputs[j]\n",
    "            classes_np = detection_classes[0].numpy()\n",
    "            scores_np = detection_scores[0].numpy()\n",
    "\n",
    "            # Store the scores > 0.5\n",
    "            scores_g50_indices = np.where(scores_np > threshold)\n",
    "            scores_g50 = scores_np[scores_g50_indices]\n",
    "\n",
    "            # Store the classes with scores > 0.5\n",
    "            classes_g50 = classes_np[scores_g50_indices]\n",
    "\n",
    "            # Turn the classes into labels\n",
    "            class_labels = class_map.loc[classes_g50].reset_index(drop=True)\n",
    "            class_scores = pd.Series(scores_g50).rename('score')\n",
    "\n",
    "            class_predictions = pd.concat([class_labels, class_scores], axis=1)\n",
    "            class_predictions = class_predictions.sort_values('score', ascending=False)\n",
    "            class_labels_pred = class_predictions['label'].value_counts()\n",
    "\n",
    "            # Check if the classes are in the vehicles or signal labels, and keep counts\n",
    "            veh_ct = class_labels_pred.loc[(class_labels_pred.index.isin(vehicles))].sum()\n",
    "            sig_ct = class_labels_pred.loc[(class_labels_pred.index.isin(signals))].sum()\n",
    "            image_pred.append([veh_ct, sig_ct])\n",
    "\n",
    "        # Get the maximum across models\n",
    "        max_veh_ct = max(m[0] for m in image_pred)\n",
    "        max_sig_ct = max(m[1] for m in image_pred)\n",
    "\n",
    "        # Get the most frequent counts across models\n",
    "        veh_ct_list = [m[0] for m in image_pred]\n",
    "        sig_ct_list = [m[1] for m in image_pred]\n",
    "        veh_ct_counter = Counter(veh_ct_list)\n",
    "        mode_veh_ct = veh_ct_counter.most_common(1)[0][0]\n",
    "        sig_ct_counter = Counter(sig_ct_list)\n",
    "        mode_sig_ct = sig_ct_counter.most_common(1)[0][0]\n",
    "\n",
    "        # print(image_pred)\n",
    "        train_pred_max.append([max_veh_ct, max_sig_ct])\n",
    "        train_pred_mode.append([mode_veh_ct, mode_sig_ct])\n",
    "        \n",
    "    return (train_pred_max, train_pred_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_mse(real_label, pred_label):\n",
    "    if len(real_label) != len(pred_label):\n",
    "        raise ValueError(\"Lists must be of equal length\")\n",
    "        \n",
    "    sq_diff = [(a-b) **2 for a, b in zip(real_label, pred_label)]\n",
    "    mse = sum(sq_diff) / len(sq_diff)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "def calculate_avg_mse(mse1, mse2):\n",
    "    return 1/2 * mse1 + 1/2 * mse2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 13)\n"
     ]
    }
   ],
   "source": [
    "# Split into train, val and test sets \n",
    "# train_data, validate_data, test_data = np.split(train_metadata.sample(frac=1, random_state=43), [int(.8*len(train_metadata)), int(.9*len(train_metadata))])\n",
    "\n",
    "train_data = train_metadata[:3000]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_veh_labels = train_data['vehicle'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sig_labels = train_data['signal'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 max -> 387.4866666666667 8.96 198.22333333333333\n",
      "20 mode -> 8.400333333333334 1.4223333333333332 4.911333333333333\n",
      "\n",
      "21 max -> 323.15766666666667 7.4286666666666665 165.29316666666668\n",
      "21 mode -> 8.395 1.4136666666666666 4.904333333333333\n",
      "\n",
      "22 max -> 265.8566666666667 6.306666666666667 136.08166666666668\n",
      "22 mode -> 8.059666666666667 1.4026666666666667 4.731166666666667\n",
      "\n",
      "23 max -> 214.97666666666666 5.450333333333333 110.2135\n",
      "23 mode -> 8.407333333333334 1.4376666666666666 4.9225\n",
      "\n",
      "24 max -> 174.04433333333333 4.755333333333334 89.39983333333333\n",
      "24 mode -> 7.694 1.454 4.574\n",
      "\n",
      "25 max -> 138.72466666666668 4.214666666666667 71.46966666666667\n",
      "25 mode -> 9.007666666666667 1.4453333333333334 5.226500000000001\n",
      "\n",
      "26 max -> 111.268 3.5566666666666666 57.412333333333336\n",
      "26 mode -> 7.794333333333333 1.454 4.6241666666666665\n",
      "\n",
      "27 max -> 88.458 3.0456666666666665 45.75183333333333\n",
      "27 mode -> 8.159 1.4813333333333334 4.820166666666667\n",
      "\n",
      "28 max -> 69.68666666666667 2.5736666666666665 36.13016666666667\n",
      "28 mode -> 8.401 1.5326666666666666 4.966833333333334\n",
      "\n",
      "29 max -> 54.50566666666667 2.231 28.368333333333336\n",
      "29 mode -> 8.357666666666667 1.5423333333333333 4.95\n",
      "\n",
      "30 max -> 42.492 2.082333333333333 22.287166666666664\n",
      "30 mode -> 8.660333333333334 1.5286666666666666 5.0945\n",
      "\n",
      "31 max -> 33.204 1.8546666666666667 17.529333333333334\n",
      "31 mode -> 8.581 1.525 5.053\n",
      "\n",
      "32 max -> 26.136333333333333 1.747 13.941666666666666\n",
      "32 mode -> 8.726 1.547 5.136500000000001\n",
      "\n",
      "33 max -> 21.318 1.65 11.484\n",
      "33 mode -> 9.095333333333333 1.5533333333333332 5.324333333333333\n",
      "\n",
      "34 max -> 17.125333333333334 1.5476666666666667 9.336500000000001\n",
      "34 mode -> 9.374666666666666 1.604 5.489333333333333\n",
      "\n",
      "35 max -> 13.952333333333334 1.507 7.729666666666667\n",
      "35 mode -> 9.475333333333333 1.6466666666666667 5.561\n",
      "\n",
      "36 max -> 11.953666666666667 1.4283333333333332 6.691\n",
      "36 mode -> 9.731666666666667 1.6593333333333333 5.6955\n",
      "\n",
      "37 max -> 10.289666666666667 1.3783333333333334 5.8340000000000005\n",
      "37 mode -> 9.83 1.6626666666666667 5.746333333333333\n",
      "\n",
      "38 max -> 8.931666666666667 1.3533333333333333 5.1425\n",
      "38 mode -> 10.077666666666667 1.682 5.879833333333334\n",
      "\n",
      "39 max -> 8.277 1.3676666666666666 4.822333333333333\n",
      "39 mode -> 10.426 1.6346666666666667 6.030333333333333\n",
      "\n",
      "40 max -> 7.742333333333334 1.361 4.551666666666667\n",
      "40 mode -> 10.564333333333334 1.6546666666666667 6.109500000000001\n",
      "\n",
      "41 max -> 7.544666666666667 1.348 4.4463333333333335\n",
      "41 mode -> 10.701 1.7026666666666668 6.201833333333334\n",
      "\n",
      "42 max -> 7.4383333333333335 1.341 4.389666666666667\n",
      "42 mode -> 10.886666666666667 1.6943333333333332 6.2905\n",
      "\n",
      "43 max -> 7.367333333333334 1.3336666666666666 4.3505\n",
      "43 mode -> 11.314 1.706 6.51\n",
      "\n",
      "44 max -> 7.411333333333333 1.324 4.367666666666667\n",
      "44 mode -> 11.601 1.7063333333333333 6.653666666666667\n",
      "\n",
      "45 max -> 7.584333333333333 1.3206666666666667 4.4525\n",
      "45 mode -> 11.837 1.741 6.789\n",
      "\n",
      "46 max -> 7.741666666666666 1.3193333333333332 4.5305\n",
      "46 mode -> 11.929 1.7233333333333334 6.8261666666666665\n",
      "\n",
      "47 max -> 7.947333333333333 1.328 4.637666666666666\n",
      "47 mode -> 12.406 1.7426666666666666 7.074333333333334\n",
      "\n",
      "48 max -> 8.121 1.3196666666666668 4.7203333333333335\n",
      "48 mode -> 12.511333333333333 1.7696666666666667 7.140499999999999\n",
      "\n",
      "49 max -> 8.260333333333334 1.346 4.803166666666667\n",
      "49 mode -> 12.742666666666667 1.767 7.254833333333333\n",
      "\n",
      "43 max: 4.3505\n",
      "CPU times: user 22min 30s, sys: 261 ms, total: 22min 30s\n",
      "Wall time: 22min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lowest = \"\"\n",
    "lowest_mse = 100000\n",
    "for i in range (20, 50):\n",
    "    train_pred_max, train_pred_mode = get_counts(.01*i)\n",
    "    \n",
    "    train_y_hat = pd.DataFrame(train_pred_max, columns=['vehicle', 'signal'])\n",
    "    agg_vehicles_pred = train_y_hat['vehicle'].tolist()\n",
    "    agg_signals_pred = train_y_hat['signal'].tolist()\n",
    "    veh_mse = calculate_mse(train_veh_labels, agg_vehicles_pred)\n",
    "    sig_mse = calculate_mse(train_sig_labels, agg_signals_pred)\n",
    "    avg_mse = calculate_avg_mse(veh_mse, sig_mse)\n",
    "    if (avg_mse < lowest_mse):\n",
    "        lowest = f\"{i} max: {avg_mse}\"\n",
    "        lowest_mse = avg_mse\n",
    "    print(i, \"max\", \"->\", veh_mse, sig_mse, avg_mse)\n",
    "    \n",
    "    train_y_hat = pd.DataFrame(train_pred_mode, columns=['vehicle', 'signal'])\n",
    "    agg_vehicles_pred = train_y_hat['vehicle'].tolist()\n",
    "    agg_signals_pred = train_y_hat['signal'].tolist()\n",
    "    veh_mse = calculate_mse(train_veh_labels, agg_vehicles_pred)\n",
    "    sig_mse = calculate_mse(train_sig_labels, agg_signals_pred)\n",
    "    avg_mse = calculate_avg_mse(veh_mse, sig_mse)\n",
    "    if (avg_mse < lowest_mse):\n",
    "        lowest = f\"{i} mode: {avg_mse}\"\n",
    "        lowest_mse = avg_mse\n",
    "    print(i, \"mode\", \"->\", veh_mse, sig_mse, avg_mse)\n",
    "    print()\n",
    "print(lowest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Blender Model on top of 7 Object Detection Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_images = 3000\n",
    "detector_outputs = []\n",
    "for i in range(0, num_images):\n",
    "    dc_tensor = None\n",
    "    ds_tensor = None\n",
    "    db_tensor = None\n",
    "    for j in range(0, len(file_jsons)):\n",
    "        curr_dc_tensor = tf.convert_to_tensor(np.array(file_jsons[str(j)][str(i)]['detection_classes']['value']))\n",
    "        curr_ds_tensor = tf.convert_to_tensor(np.array(file_jsons[str(j)][str(i)]['detection_scores']['value']))\n",
    "        curr_db_tensor = tf.convert_to_tensor(np.array(file_jsons[str(j)][str(i)]['detection_boxes']['value']))\n",
    "        curr_dc_tensor = tf.slice(curr_dc_tensor, [0,0], [1,30])  # 100\n",
    "        curr_ds_tensor = tf.slice(curr_ds_tensor, [0,0], [1,30])\n",
    "        curr_db_tensor = tf.slice(curr_db_tensor, [0,0,0], [1,30,4])\n",
    "        if dc_tensor is None:\n",
    "            dc_tensor = curr_dc_tensor\n",
    "            ds_tensor = curr_ds_tensor\n",
    "            db_tensor = curr_db_tensor\n",
    "        else:\n",
    "            dc_tensor = tf.concat([dc_tensor, curr_dc_tensor], 1)\n",
    "            ds_tensor = tf.concat([ds_tensor, curr_ds_tensor], 1)\n",
    "            db_tensor = tf.concat([db_tensor, curr_db_tensor], 1)\n",
    "    detector_outputs.append((dc_tensor, ds_tensor, db_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(detector_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(file_jsons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_veh_labels = train_data['vehicle'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sig_labels = train_data['signal'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_car_labels = train_data['car'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_images = len(detector_outputs)\n",
    "labels = train_car_labels\n",
    "\n",
    "def build_generator_labeled():\n",
    "    def generator():\n",
    "        for i in range(0, num_images):\n",
    "\n",
    "            current_output = detector_outputs[i]\n",
    "            model_input = (tf.reshape(current_output[0], [210]), tf.reshape(current_output[1], [210]) ) # tf.reshape(current_output[2], [210, 4]\n",
    "\n",
    "            model_output = tf.convert_to_tensor(np.array([labels[i]]))\n",
    "\n",
    "            yield (model_input, model_output)\n",
    "\n",
    "    return generator\n",
    "\n",
    "# See Tensorflow Dataset\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "def build_dataset_labeled():\n",
    "    scores_signature = tf.TensorSpec(shape=(210,), dtype=tf.float32)  # type: ignore\n",
    "    # boxes_signature = tf.TensorSpec(shape=(210,4), dtype=tf.float32)\n",
    "\n",
    "    model_input = (scores_signature, scores_signature) #, boxes_signature\n",
    "    model_output = tf.TensorSpec(shape=(1,), dtype=tf.int32)  # type: ignore\n",
    "\n",
    "    dataset_signature = (model_input, model_output)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        build_generator_labeled(), \n",
    "        output_signature=dataset_signature\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = build_dataset_labeled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((<tf.Tensor: shape=(210,), dtype=float32, numpy=\n",
      "array([85.,  3.,  8., 13., 85., 85.,  3.,  1.,  3., 13., 85.,  1.,  8.,\n",
      "       85.,  3.,  1.,  1.,  3.,  3.,  1.,  3.,  3.,  2.,  8.,  6.,  3.,\n",
      "        3.,  2.,  3.,  3., 85.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
      "        3.,  3.,  3., 85.,  3.,  3.,  3.,  1.,  3.,  3.,  3.,  8.,  3.,\n",
      "        3.,  8.,  8.,  3.,  1.,  3.,  3.,  3., 85.,  3.,  8.,  3.,  3.,\n",
      "       65.,  3.,  3.,  8., 44.,  3., 44.,  3.,  3.,  6.,  3.,  3.,  3.,\n",
      "       65., 81., 65.,  8.,  1.,  1.,  3.,  3.,  3.,  8.,  8., 63., 85.,\n",
      "        3.,  3.,  3.,  3.,  8.,  3.,  3.,  3.,  3.,  3.,  3., 15.,  8.,\n",
      "        3.,  3.,  8.,  3.,  3.,  3.,  3.,  2.,  3.,  8.,  8.,  6.,  3.,\n",
      "        3.,  3.,  3., 85.,  3., 13.,  8.,  3.,  8.,  3.,  3.,  8.,  3.,\n",
      "        3.,  3.,  3.,  3., 14.,  3.,  8., 14.,  3.,  3.,  3.,  8.,  3.,\n",
      "        3.,  8.,  1.,  3.,  3., 85.,  1., 85.,  3.,  3.,  3.,  3.,  8.,\n",
      "        3.,  3.,  3.,  8.,  3.,  3.,  3.,  3.,  3., 85.,  3.,  3.,  3.,\n",
      "        3., 64.,  3.,  3.,  3., 85.,  3.,  3.,  1.,  3., 44., 85., 13.,\n",
      "        3.,  3.,  8.,  3.,  3.,  3.,  3., 44.,  8.,  3.,  6.,  3.,  8.,\n",
      "        3., 44.,  3.,  6.,  1.,  8.,  3.,  8.,  8., 65.,  6.,  1.,  1.,\n",
      "        6., 10.], dtype=float32)>, <tf.Tensor: shape=(210,), dtype=float32, numpy=\n",
      "array([0.99851567, 0.99339855, 0.9515692 , 0.8311694 , 0.33092114,\n",
      "       0.19277102, 0.17211467, 0.12453531, 0.11060002, 0.10592768,\n",
      "       0.10377996, 0.09627533, 0.07897714, 0.04710349, 0.0422769 ,\n",
      "       0.03916119, 0.03733099, 0.02389889, 0.01618596, 0.01544177,\n",
      "       0.01543053, 0.01374685, 0.01297493, 0.01229193, 0.01087417,\n",
      "       0.01037075, 0.01034418, 0.00966783, 0.00931691, 0.0090451 ,\n",
      "       0.7054738 , 0.6742964 , 0.46790662, 0.4511003 , 0.3628717 ,\n",
      "       0.3585187 , 0.35552844, 0.35172373, 0.3456402 , 0.33668602,\n",
      "       0.33220723, 0.3242144 , 0.32192147, 0.31376758, 0.29786158,\n",
      "       0.28976974, 0.2887982 , 0.2697973 , 0.26909453, 0.2688181 ,\n",
      "       0.25862178, 0.25606716, 0.25605023, 0.24968708, 0.24874878,\n",
      "       0.24812552, 0.2455293 , 0.24405402, 0.22735336, 0.22670063,\n",
      "       0.9991284 , 0.8633793 , 0.46140766, 0.39659774, 0.3690474 ,\n",
      "       0.27604717, 0.21107773, 0.19258028, 0.11135715, 0.08681581,\n",
      "       0.08539024, 0.07530803, 0.0689403 , 0.06037637, 0.05646268,\n",
      "       0.05573157, 0.05425879, 0.04829361, 0.04265258, 0.03729414,\n",
      "       0.03568856, 0.03560634, 0.03277033, 0.03043978, 0.03038735,\n",
      "       0.02964532, 0.02893173, 0.02858213, 0.02760287, 0.02618837,\n",
      "       0.7790941 , 0.4453174 , 0.40974474, 0.40744656, 0.39520326,\n",
      "       0.37433285, 0.34373376, 0.3387261 , 0.30191672, 0.28023472,\n",
      "       0.2610942 , 0.25474018, 0.24888596, 0.22580647, 0.21826977,\n",
      "       0.21399689, 0.20154014, 0.19844985, 0.19072199, 0.19000489,\n",
      "       0.18566084, 0.18348905, 0.17642662, 0.17496541, 0.1748445 ,\n",
      "       0.17447296, 0.17057493, 0.16966715, 0.16464612, 0.15553749,\n",
      "       0.9983924 , 0.97511375, 0.89739215, 0.5200764 , 0.3431678 ,\n",
      "       0.29344383, 0.24778505, 0.23001976, 0.219607  , 0.19316635,\n",
      "       0.16697694, 0.15600206, 0.13201317, 0.10306949, 0.07849953,\n",
      "       0.05967248, 0.04521545, 0.04064522, 0.03955108, 0.03776303,\n",
      "       0.03746054, 0.03609781, 0.03444258, 0.03178469, 0.03068518,\n",
      "       0.02959505, 0.02958528, 0.02770964, 0.02274346, 0.02151928,\n",
      "       0.78864384, 0.40852377, 0.31982526, 0.30685917, 0.30372   ,\n",
      "       0.29776317, 0.2821015 , 0.2803551 , 0.27488977, 0.2732905 ,\n",
      "       0.256694  , 0.25604343, 0.23033181, 0.2157385 , 0.20941141,\n",
      "       0.20826772, 0.2066215 , 0.20575821, 0.19819891, 0.19085684,\n",
      "       0.18523106, 0.1798476 , 0.17936799, 0.17909083, 0.17695388,\n",
      "       0.17411429, 0.1707564 , 0.17003992, 0.16873178, 0.16857168,\n",
      "       0.9978701 , 0.86921734, 0.6239908 , 0.5675309 , 0.40352142,\n",
      "       0.28828695, 0.19644345, 0.1657546 , 0.15906876, 0.14530122,\n",
      "       0.13252693, 0.12755364, 0.10598952, 0.09177922, 0.07834806,\n",
      "       0.07084505, 0.067832  , 0.06408259, 0.05875757, 0.05383314,\n",
      "       0.05366348, 0.05277022, 0.04720665, 0.04417037, 0.04255731,\n",
      "       0.03804633, 0.03779875, 0.03561285, 0.0348717 , 0.03102624],\n",
      "      dtype=float32)>), <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validate, and test sets \n",
    "\n",
    "train_size = 2000 \n",
    "validate_size = 500\n",
    "test_size = 500\n",
    "\n",
    "train_set = a.take(train_size)\n",
    "validate_set = a.skip(train_size).take(validate_size)\n",
    "test_set = a.skip(train_size).skip(validate_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set_batch = train_set.batch(16)\n",
    "validate_set_batch = validate_set.batch(16)\n",
    "test_set_batch = test_set.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 210)]        0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 210)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 64)           13504       ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 64)           13504       ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 64)          256         ['dense_12[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 64)          256         ['dense_13[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 64)           0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 64)           0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 128)          0           ['dropout_6[0][0]',              \n",
      "                                                                  'dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 64)           8256        ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1)            65          ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 35,841\n",
      "Trainable params: 35,585\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = [\n",
    "    tf.keras.layers.Input((210,)),\n",
    "    tf.keras.layers.Input((210,)),\n",
    "    # tf.keras.layers.Input((120,4)),\n",
    "]\n",
    "\n",
    "# Process classes\n",
    "x_classes = tf.keras.layers.Dense(64, activation='relu')(inputs[0])\n",
    "# x_classes = tf.keras.layers.Dense(64, activation='relu')(x_classes)\n",
    "x_classes = tf.keras.layers.BatchNormalization()(x_classes)\n",
    "x_classes = tf.keras.layers.Dropout(0.2)(x_classes)\n",
    "# x_classes = tf.keras.layers.Dense(64, activation='relu')(x_classes)\n",
    "\n",
    "# Process scores\n",
    "x_scores = tf.keras.layers.Dense(64, activation='relu')(inputs[1])\n",
    "# x_scores = tf.keras.layers.Dense(64, activation='relu')(x_scores)\n",
    "x_scores = tf.keras.layers.BatchNormalization()(x_scores)\n",
    "x_scores = tf.keras.layers.Dropout(0.2)(x_scores)\n",
    "# x_scores = tf.keras.layers.Dense(64, activation='relu')(x_scores)\n",
    "\n",
    "# Process boxes\n",
    "# x_boxes = tf.keras.layers.Flatten()(inputs[2])\n",
    "# x_boxes = tf.keras.layers.Dense(128, activation='relu')(x_boxes)\n",
    "# x_boxes = tf.keras.layers.Dense(64, activation='relu')(x_boxes)\n",
    "# x_boxes = tf.keras.layers.BatchNormalization()(x_boxes)\n",
    "# x_boxes = tf.keras.layers.Dropout(0.2)(x_boxes)\n",
    "# x_boxes = tf.keras.layers.Dense(64, activation='relu')(x_boxes)\n",
    "\n",
    "# Combine\n",
    "outputs = tf.keras.layers.Concatenate(axis=-1)([x_classes, x_scores])\n",
    "outputs = tf.keras.layers.Dense(64, activation='relu')(outputs)\n",
    "# outputs = tf.keras.layers.BatchNormalization()(outputs)\n",
    "# outputs = tf.keras.layers.Dropout(0.2)(outputs)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(outputs)\n",
    "\n",
    "# Overall model\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 4s 27ms/step - loss: 8.3391 - mse: 8.3391 - val_loss: 7.9968 - val_mse: 7.9968\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 8.0738 - mse: 8.0738 - val_loss: 7.9549 - val_mse: 7.9549\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 8.0267 - mse: 8.0267 - val_loss: 7.9504 - val_mse: 7.9504\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 8.0041 - mse: 8.0041 - val_loss: 7.9680 - val_mse: 7.9680\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 7.9763 - mse: 7.9763 - val_loss: 8.0090 - val_mse: 8.0090\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 7.9648 - mse: 7.9648 - val_loss: 7.9781 - val_mse: 7.9781\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 7.9409 - mse: 7.9409 - val_loss: 8.0210 - val_mse: 8.0210\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 7.9286 - mse: 7.9286 - val_loss: 8.0413 - val_mse: 8.0413\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 7.9212 - mse: 7.9212 - val_loss: 8.0543 - val_mse: 8.0543\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 7.9089 - mse: 7.9089 - val_loss: 8.1165 - val_mse: 8.1165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3341242b90>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "verbose = 1\n",
    "\n",
    "# Use early_stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model.fit(\n",
    "        train_set_batch,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=validate_set_batch,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 13ms/step - loss: 8.7992 - mse: 8.7992\n",
      "Test MSE: [8.7991943359375, 8.7991943359375]\n"
     ]
    }
   ],
   "source": [
    "test_eval = model.evaluate(test_set_batch)\n",
    "print(\"Test MSE:\", test_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59 s, sys: 3.03 s, total: 1min 2s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import tensorflow_hub as hub\n",
    "\n",
    "faster_rcnn_inception_resnet_640 = hub.load(\"https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_640x640/1\")\n",
    "# faster_rcnn_inception_resnet_1024 = hub.load(\"https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1\")\n",
    "faster_rcnn_resnet152 = hub.load(\"https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_640x640/1\")\n",
    "# faster_rcnn_resnet101 = hub.load(\"https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_640x640/1\")\n",
    "# faster_rcnn_resnet50 = hub.load(\"https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_640x640/1\")\n",
    "# ssd_mobilenet_v1_fpn = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v1/fpn_640x640/1\")\n",
    "ssd_mobilenet_v2 = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
    "ssd_mobilenet_v2_fpnlite = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate score data\n",
    "\n",
    "def build_generator_score():\n",
    "    metadata = pd.read_csv('carnet_dataset/score/metadata.csv')\n",
    "    \n",
    "    for _, row in metadata.iterrows():\n",
    "        scoring_path = 'carnet_dataset/score/images/' + row['file_name']\n",
    "        model_input = np.array(Image.open(scoring_path)).astype(np.uint8)\n",
    "        yield model_input\n",
    "\n",
    "def build_dataset_score() -> tf.data.Dataset:\n",
    "    model_input = tf.TensorSpec(shape=(224, 224, 3), dtype=tf.uint8)  # type: ignore\n",
    "\n",
    "    dataset_signature = model_input\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        build_generator_score, \n",
    "        output_signature=dataset_signature\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Batch score set \n",
    "score_batch = build_dataset_score().batch(1)\n",
    "print(next(iter(score_batch)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "# Extract score images for detector\n",
    "score_images = []\n",
    "\n",
    "for score_image in score_batch:\n",
    "    score_images.append(np.expand_dims(np.array(score_image), 0))\n",
    "    \n",
    "score_images = tf.concat(score_images, axis=0)\n",
    "print(type(score_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5766, 1, 224, 224, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(score_images)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object detection model: 0\n",
      "# of images: 5766\n",
      "Object detection model: 1\n",
      "# of images: 5766\n",
      "Object detection model: 2\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[1,96,160,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node ssd_mobile_net_v2fpn_keras_feature_extractor/functional_1/block_1_expand_BN/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[StatefulPartitionedCall/Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/Reshape_8/_50]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[1,96,160,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node ssd_mobile_net_v2fpn_keras_feature_extractor/functional_1/block_1_expand_BN/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_restored_function_body_445307]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:7\u001b[0m\n",
      "File \u001b[0;32m<timed exec>:7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "File \u001b[0;32m/app/conda/envs/collegium/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:744\u001b[0m, in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_attribute\u001b[39m(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 744\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/conda/envs/collegium/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/app/conda/envs/collegium/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[1,96,160,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node ssd_mobile_net_v2fpn_keras_feature_extractor/functional_1/block_1_expand_BN/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[StatefulPartitionedCall/Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/Reshape_8/_50]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[1,96,160,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node ssd_mobile_net_v2fpn_keras_feature_extractor/functional_1/block_1_expand_BN/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_restored_function_body_445307]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "modules = [faster_rcnn_inception_resnet_640, ssd_mobilenet_v2, ssd_mobilenet_v2_fpnlite, faster_rcnn_resnet152]\n",
    "\n",
    "i=0\n",
    "results_list = []\n",
    "for mod in modules:\n",
    "    print(f'Object detection model: {i}')\n",
    "    results = [mod(x) for x in score_images]\n",
    "    results_list.append(results)\n",
    "    print(f'# of images: {len(results)}')\n",
    "    i+=1\n",
    "    \n",
    "print(len(results_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object detection model: 0\n",
      "# of images: 5766\n",
      "Object detection model: 1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[1,96,160,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node ssd_mobile_net_v2fpn_keras_feature_extractor/functional_1/block_1_expand_BN/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[StatefulPartitionedCall/Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/Reshape_8/_50]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[1,96,160,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node ssd_mobile_net_v2fpn_keras_feature_extractor/functional_1/block_1_expand_BN/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_restored_function_body_445307]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:7\u001b[0m\n",
      "File \u001b[0;32m<timed exec>:7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "File \u001b[0;32m/app/conda/envs/collegium/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:744\u001b[0m, in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_attribute\u001b[39m(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 744\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/conda/envs/collegium/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/app/conda/envs/collegium/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[1,96,160,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node ssd_mobile_net_v2fpn_keras_feature_extractor/functional_1/block_1_expand_BN/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[StatefulPartitionedCall/Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/Reshape_8/_50]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED:  OOM when allocating tensor with shape[1,96,160,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node ssd_mobile_net_v2fpn_keras_feature_extractor/functional_1/block_1_expand_BN/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_restored_function_body_445307]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "modules = [faster_rcnn_resnet152, ssd_mobilenet_v2_fpnlite]\n",
    "\n",
    "i=0\n",
    "results_list = []\n",
    "for mod in modules:\n",
    "    print(f'Object detection model: {i}')\n",
    "    results = [mod(x) for x in score_images]\n",
    "    results_list.append(results)\n",
    "    print(f'# of images: {len(results)}')\n",
    "    i+=1\n",
    "    \n",
    "print(len(results_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object detection model: 0\n",
      "# of images: 5766\n",
      "1\n",
      "CPU times: user 32min 49s, sys: 3min 49s, total: 36min 39s\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# ssd_mobilenet_v1_fpn = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v1/fpn_640x640/1\")\n",
    "modules = [ssd_mobilenet_v2_fpnlite]\n",
    "\n",
    "i=0\n",
    "results_list = []\n",
    "for mod in modules:\n",
    "    print(f'Object detection model: {i}')\n",
    "    results = [mod(x) for x in score_images]\n",
    "    results_list.append(results)\n",
    "    print(f'# of images: {len(results)}')\n",
    "    i+=1\n",
    "    \n",
    "print(len(results_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766\n",
      "8\n",
      "dict_keys(['raw_detection_scores', 'detection_anchor_indices', 'raw_detection_boxes', 'num_detections', 'detection_classes', 'detection_scores', 'detection_boxes', 'detection_multiclass_scores'])\n"
     ]
    }
   ],
   "source": [
    "print(len(results_list[0])) # number of images\n",
    "print(len(results_list[0][0].keys())) # number of items for each image\n",
    "print(results_list[0][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_images = len(results_list[0])\n",
    "detector_result_dict = {}\n",
    "for i in list(range(num_images)):\n",
    "    detector_result_dict[i] = {'detection_classes': {},\n",
    "                               'detection_boxes': {},\n",
    "                               'detection_scores': {}\n",
    "                              }\n",
    "    \n",
    "    detector_result_dict[i]['detection_classes']['shape'] = results_list[0][i]['detection_classes'].shape.as_list()\n",
    "    detector_result_dict[i]['detection_classes']['value'] = results_list[0][i]['detection_classes'].numpy().tolist()\n",
    "    \n",
    "    detector_result_dict[i]['detection_boxes']['shape'] = results_list[0][i]['detection_boxes'].shape.as_list()\n",
    "    detector_result_dict[i]['detection_boxes']['value'] = results_list[0][i]['detection_boxes'].numpy().tolist()\n",
    "    \n",
    "    detector_result_dict[i]['detection_scores']['shape'] = results_list[0][i]['detection_scores'].shape.as_list()\n",
    "    detector_result_dict[i]['detection_scores']['value'] = results_list[0][i]['detection_scores'].numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766\n"
     ]
    }
   ],
   "source": [
    "print(len(detector_result_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specifying the file path to save the JSON file\n",
    "# file_path = 'detector_result_score1.json'\n",
    "# file_path = 'detector_result_score3.json'\n",
    "file_path = 'detector_result_score4.json'\n",
    "\n",
    "# Saving the dictionary to a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(detector_result_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_images = len(results_list[0])\n",
    "detector_result_dict = {}\n",
    "for i in list(range(num_images)):\n",
    "    detector_result_dict[i] = {'detection_classes': {},\n",
    "                               'detection_boxes': {},\n",
    "                               'detection_scores': {}\n",
    "                              }\n",
    "    \n",
    "    detector_result_dict[i]['detection_classes']['shape'] = results_list[1][i]['detection_classes'].shape.as_list()\n",
    "    detector_result_dict[i]['detection_classes']['value'] = results_list[1][i]['detection_classes'].numpy().tolist()\n",
    "    \n",
    "    detector_result_dict[i]['detection_boxes']['shape'] = results_list[1][i]['detection_boxes'].shape.as_list()\n",
    "    detector_result_dict[i]['detection_boxes']['value'] = results_list[1][i]['detection_boxes'].numpy().tolist()\n",
    "    \n",
    "    detector_result_dict[i]['detection_scores']['shape'] = results_list[1][i]['detection_scores'].shape.as_list()\n",
    "    detector_result_dict[i]['detection_scores']['value'] = results_list[1][i]['detection_scores'].numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766\n"
     ]
    }
   ],
   "source": [
    "print(len(detector_result_dict.keys()))\n",
    "\n",
    "# Specifying the file path to save the JSON file\n",
    "file_path = 'detector_result_score2.json'\n",
    "\n",
    "# Saving the dictionary to a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(detector_result_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object detection model: 0\n",
      "# of images: 5766\n",
      "1\n",
      "CPU times: user 32min 49s, sys: 3min 49s, total: 36min 39s\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# ssd_mobilenet_v1_fpn = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v1/fpn_640x640/1\")\n",
    "modules = [ssd_mobilenet_v2_fpnlite]\n",
    "\n",
    "i=0\n",
    "results_list = []\n",
    "for mod in modules:\n",
    "    print(f'Object detection model: {i}')\n",
    "    results = [mod(x) for x in score_images]\n",
    "    results_list.append(results)\n",
    "    print(f'# of images: {len(results)}')\n",
    "    i+=1\n",
    "    \n",
    "print(len(results_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766\n",
      "8\n",
      "dict_keys(['raw_detection_scores', 'detection_anchor_indices', 'raw_detection_boxes', 'num_detections', 'detection_classes', 'detection_scores', 'detection_boxes', 'detection_multiclass_scores'])\n"
     ]
    }
   ],
   "source": [
    "print(len(results_list[0])) # number of images\n",
    "print(len(results_list[0][0].keys())) # number of items for each image\n",
    "print(results_list[0][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = 'detector_result_score1.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    detector_result_score1 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766\n"
     ]
    }
   ],
   "source": [
    "print(len(detector_result_score1.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detection_classes': {'shape': [1, 100],\n",
       "  'value': [[38.0,\n",
       "    38.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    38.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    38.0,\n",
       "    3.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    19.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    38.0,\n",
       "    38.0,\n",
       "    1.0,\n",
       "    38.0,\n",
       "    38.0,\n",
       "    21.0,\n",
       "    8.0,\n",
       "    1.0,\n",
       "    38.0,\n",
       "    1.0,\n",
       "    38.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    38.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    16.0,\n",
       "    3.0,\n",
       "    38.0,\n",
       "    1.0,\n",
       "    38.0,\n",
       "    19.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    38.0,\n",
       "    38.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    38.0,\n",
       "    1.0,\n",
       "    38.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    38.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    38.0,\n",
       "    2.0,\n",
       "    1.0,\n",
       "    38.0,\n",
       "    16.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    38.0,\n",
       "    21.0,\n",
       "    3.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    2.0,\n",
       "    2.0,\n",
       "    16.0,\n",
       "    15.0,\n",
       "    3.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    62.0,\n",
       "    1.0,\n",
       "    62.0,\n",
       "    21.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    62.0,\n",
       "    1.0,\n",
       "    19.0,\n",
       "    1.0,\n",
       "    38.0,\n",
       "    16.0,\n",
       "    19.0,\n",
       "    19.0,\n",
       "    38.0,\n",
       "    3.0,\n",
       "    16.0,\n",
       "    16.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0,\n",
       "    1.0]]},\n",
       " 'detection_boxes': {'shape': [1, 100, 4],\n",
       "  'value': [[[0.4471503794193268,\n",
       "     0.7834394574165344,\n",
       "     0.47893473505973816,\n",
       "     0.8020915985107422],\n",
       "    [0.18968701362609863,\n",
       "     0.7611597776412964,\n",
       "     0.21968837082386017,\n",
       "     0.7895683646202087],\n",
       "    [0.7223224639892578,\n",
       "     0.28647372126579285,\n",
       "     0.7902591824531555,\n",
       "     0.32092347741127014],\n",
       "    [0.7418736219406128,\n",
       "     0.3247082829475403,\n",
       "     0.7872139811515808,\n",
       "     0.35019636154174805],\n",
       "    [0.6469044089317322,\n",
       "     0.6436864733695984,\n",
       "     0.6794504523277283,\n",
       "     0.6779873371124268],\n",
       "    [0.7333341836929321,\n",
       "     0.011372491717338562,\n",
       "     0.7887970209121704,\n",
       "     0.037465114146471024],\n",
       "    [0.7446868419647217,\n",
       "     0.07289623469114304,\n",
       "     0.7831435799598694,\n",
       "     0.09885262697935104],\n",
       "    [0.7353038787841797,\n",
       "     0.262132853269577,\n",
       "     0.7978167533874512,\n",
       "     0.2935175597667694],\n",
       "    [0.7374968528747559,\n",
       "     0.007082588970661163,\n",
       "     0.7882021069526672,\n",
       "     0.029783641919493675],\n",
       "    [0.44490453600883484,\n",
       "     0.7810341715812683,\n",
       "     0.49002647399902344,\n",
       "     0.8069067001342773],\n",
       "    [0.7418248057365417,\n",
       "     0.5338401198387146,\n",
       "     0.7701199054718018,\n",
       "     0.5620474219322205],\n",
       "    [0.7264726758003235,\n",
       "     0.2697400748729706,\n",
       "     0.7960957884788513,\n",
       "     0.3202621340751648],\n",
       "    [0.7290430665016174,\n",
       "     0.27470776438713074,\n",
       "     0.7911912798881531,\n",
       "     0.3031475245952606],\n",
       "    [0.7348151803016663,\n",
       "     0.02661474421620369,\n",
       "     0.786453902721405,\n",
       "     0.04724409803748131],\n",
       "    [0.6804834604263306,\n",
       "     0.23255763947963715,\n",
       "     0.7721682786941528,\n",
       "     0.26555129885673523],\n",
       "    [0.7643119096755981,\n",
       "     0.6897363066673279,\n",
       "     0.7887797355651855,\n",
       "     0.7134131193161011],\n",
       "    [0.7360786199569702,\n",
       "     0.2528272569179535,\n",
       "     0.8006052374839783,\n",
       "     0.282623291015625],\n",
       "    [0.7424642443656921,\n",
       "     0.32725393772125244,\n",
       "     0.7765964865684509,\n",
       "     0.3469027280807495],\n",
       "    [0.7276124358177185,\n",
       "     0.29191726446151733,\n",
       "     0.7905917167663574,\n",
       "     0.3352808654308319],\n",
       "    [0.6443186402320862,\n",
       "     0.6382816433906555,\n",
       "     0.7075580954551697,\n",
       "     0.6812785267829895],\n",
       "    [0.482966810464859,\n",
       "     0.4386787414550781,\n",
       "     0.4975535571575165,\n",
       "     0.45160648226737976],\n",
       "    [0.7640566229820251,\n",
       "     0.6577333211898804,\n",
       "     0.7849725484848022,\n",
       "     0.6732819080352783],\n",
       "    [0.4452945291996002,\n",
       "     0.7853861451148987,\n",
       "     0.4618098735809326,\n",
       "     0.7999981641769409],\n",
       "    [0.18145452439785004,\n",
       "     0.6169443130493164,\n",
       "     0.4962072968482971,\n",
       "     0.9705097079277039],\n",
       "    [0.7643119096755981,\n",
       "     0.6897363066673279,\n",
       "     0.7887797355651855,\n",
       "     0.7134131193161011],\n",
       "    [0.7418248057365417,\n",
       "     0.5338401198387146,\n",
       "     0.7701199054718018,\n",
       "     0.5620474219322205],\n",
       "    [0.7161862254142761,\n",
       "     0.2785310447216034,\n",
       "     0.7902829647064209,\n",
       "     0.3318460285663605],\n",
       "    [0.4815117418766022,\n",
       "     0.43668195605278015,\n",
       "     0.4951741695404053,\n",
       "     0.4487338066101074],\n",
       "    [0.7643119096755981,\n",
       "     0.6897363066673279,\n",
       "     0.7887797355651855,\n",
       "     0.7134131193161011],\n",
       "    [0.18673299252986908,\n",
       "     0.7534584403038025,\n",
       "     0.20280669629573822,\n",
       "     0.7685357928276062],\n",
       "    [0.7429222464561462,\n",
       "     0.0544593520462513,\n",
       "     0.7865758538246155,\n",
       "     0.0994054526090622],\n",
       "    [0.7209681868553162,\n",
       "     0.0075768353417515755,\n",
       "     0.8233975768089294,\n",
       "     0.3780229985713959],\n",
       "    [0.7420676946640015,\n",
       "     0.002442257246002555,\n",
       "     0.7917748093605042,\n",
       "     0.02135017327964306],\n",
       "    [0.4312755763530731,\n",
       "     0.5101908445358276,\n",
       "     0.7325534820556641,\n",
       "     0.9577968716621399],\n",
       "    [0.7205216288566589,\n",
       "     0.28235480189323425,\n",
       "     0.7626016736030579,\n",
       "     0.3066384494304657],\n",
       "    [0.7151259779930115,\n",
       "     0.1854417473077774,\n",
       "     0.7789131999015808,\n",
       "     0.21607272326946259],\n",
       "    [0.18832746148109436,\n",
       "     0.7582323551177979,\n",
       "     0.21852807700634003,\n",
       "     0.7892253398895264],\n",
       "    [0.7667196989059448,\n",
       "     0.425429105758667,\n",
       "     0.7853662371635437,\n",
       "     0.45282769203186035],\n",
       "    [0.19076448678970337,\n",
       "     0.7522466778755188,\n",
       "     0.21152423322200775,\n",
       "     0.767597496509552],\n",
       "    [0.7451953887939453,\n",
       "     0.0494656078517437,\n",
       "     0.7864484190940857,\n",
       "     0.07523635774850845],\n",
       "    [0.6455379128456116,\n",
       "     0.6476096510887146,\n",
       "     0.6706368327140808,\n",
       "     0.6797531247138977],\n",
       "    [0.7632755041122437,\n",
       "     0.6697208881378174,\n",
       "     0.7905437350273132,\n",
       "     0.7151493430137634],\n",
       "    [0.7186608910560608,\n",
       "     0.292623370885849,\n",
       "     0.7442317605018616,\n",
       "     0.31565946340560913],\n",
       "    [0.7656998634338379,\n",
       "     0.3901078402996063,\n",
       "     0.7903391122817993,\n",
       "     0.4064600169658661],\n",
       "    [0.11232887953519821,\n",
       "     0.4564877450466156,\n",
       "     0.4956483840942383,\n",
       "     0.9701277017593384],\n",
       "    [0.18824845552444458,\n",
       "     0.7701051831245422,\n",
       "     0.20633721351623535,\n",
       "     0.7912363409996033],\n",
       "    [0.7386274337768555,\n",
       "     0.07665571570396423,\n",
       "     0.7767260670661926,\n",
       "     0.09719222038984299],\n",
       "    [0.7606188058853149,\n",
       "     0.6544932723045349,\n",
       "     0.7834402918815613,\n",
       "     0.6774336695671082],\n",
       "    [0.4495556354522705,\n",
       "     0.780697226524353,\n",
       "     0.46944642066955566,\n",
       "     0.7974919080734253],\n",
       "    [0.7179754376411438,\n",
       "     0.2868647575378418,\n",
       "     0.7443607449531555,\n",
       "     0.3079953193664551],\n",
       "    [0.4424150586128235,\n",
       "     0.7835857272148132,\n",
       "     0.4967316687107086,\n",
       "     0.8186073303222656],\n",
       "    [0.7307834029197693,\n",
       "     0.023882687091827393,\n",
       "     0.7893574237823486,\n",
       "     0.06104530766606331],\n",
       "    [0.7424750924110413,\n",
       "     0.5343748331069946,\n",
       "     0.772369921207428,\n",
       "     0.5632508397102356],\n",
       "    [0.03464852645993233,\n",
       "     0.58956378698349,\n",
       "     0.2858823835849762,\n",
       "     0.9757440686225891],\n",
       "    [0.7094265222549438,\n",
       "     0.012873196974396706,\n",
       "     0.7986878752708435,\n",
       "     0.49575120210647583],\n",
       "    [0.7667196989059448,\n",
       "     0.425429105758667,\n",
       "     0.7853662371635437,\n",
       "     0.45282769203186035],\n",
       "    [0.6632169485092163,\n",
       "     0.008870315738022327,\n",
       "     0.8414351344108582,\n",
       "     0.4355306327342987],\n",
       "    [0.7665234804153442,\n",
       "     0.40299421548843384,\n",
       "     0.7832232713699341,\n",
       "     0.42083659768104553],\n",
       "    [0.39877739548683167,\n",
       "     0.6014403104782104,\n",
       "     0.45960912108421326,\n",
       "     0.7686889171600342],\n",
       "    [0.7379561066627502,\n",
       "     0.2629009485244751,\n",
       "     0.7969275116920471,\n",
       "     0.31212761998176575],\n",
       "    [0.7375029921531677,\n",
       "     0.2834244966506958,\n",
       "     0.8011654019355774,\n",
       "     0.32523468136787415],\n",
       "    [0.19155435264110565,\n",
       "     0.7675229907035828,\n",
       "     0.22247610986232758,\n",
       "     0.7995224595069885],\n",
       "    [0.4821547567844391,\n",
       "     0.43721356987953186,\n",
       "     0.4965765178203583,\n",
       "     0.4496064782142639],\n",
       "    [0.7683016657829285,\n",
       "     0.3978463411331177,\n",
       "     0.7905681729316711,\n",
       "     0.41729655861854553],\n",
       "    [0.7021175026893616,\n",
       "     0.9676370620727539,\n",
       "     0.7744029760360718,\n",
       "     0.9979782104492188],\n",
       "    [0.4838946759700775,\n",
       "     0.434091717004776,\n",
       "     0.4979134202003479,\n",
       "     0.4469585120677948],\n",
       "    [0.7632755041122437,\n",
       "     0.6697208881378174,\n",
       "     0.7905437350273132,\n",
       "     0.7151493430137634],\n",
       "    [0.7584214806556702,\n",
       "     0.4011683464050293,\n",
       "     0.7860707640647888,\n",
       "     0.45888519287109375],\n",
       "    [0.671673059463501,\n",
       "     0.22783629596233368,\n",
       "     0.7613450884819031,\n",
       "     0.25217774510383606],\n",
       "    [0.6873624324798584,\n",
       "     0.24048073589801788,\n",
       "     0.7563696503639221,\n",
       "     0.26756250858306885],\n",
       "    [0.7632810473442078,\n",
       "     0.3924797475337982,\n",
       "     0.7846376299858093,\n",
       "     0.40603113174438477],\n",
       "    [0.7427610754966736,\n",
       "     0.2536245286464691,\n",
       "     0.8001908659934998,\n",
       "     0.28884729743003845],\n",
       "    [0.7348803281784058,\n",
       "     0.2723786532878876,\n",
       "     0.7936985492706299,\n",
       "     0.32978326082229614],\n",
       "    [0.1886177361011505,\n",
       "     0.7624710202217102,\n",
       "     0.21226266026496887,\n",
       "     0.7857956290245056],\n",
       "    [0.7348803281784058,\n",
       "     0.2723786532878876,\n",
       "     0.7936985492706299,\n",
       "     0.32978326082229614],\n",
       "    [0.7608110904693604,\n",
       "     0.434408038854599,\n",
       "     0.7846875786781311,\n",
       "     0.4606602191925049],\n",
       "    [0.7278398275375366,\n",
       "     0.18257324397563934,\n",
       "     0.7742794752120972,\n",
       "     0.20156720280647278],\n",
       "    [0.732615053653717,\n",
       "     0.018814658746123314,\n",
       "     0.7892648577690125,\n",
       "     0.09089189767837524],\n",
       "    [0.7465083599090576,\n",
       "     0.06998679041862488,\n",
       "     0.7833899259567261,\n",
       "     0.0947401374578476],\n",
       "    [0.7022436857223511,\n",
       "     0.18990926444530487,\n",
       "     0.7693151235580444,\n",
       "     0.21507887542247772],\n",
       "    [0.7374968528747559,\n",
       "     0.007082588970661163,\n",
       "     0.7882021069526672,\n",
       "     0.029783641919493675],\n",
       "    [0.7640566229820251,\n",
       "     0.6577333211898804,\n",
       "     0.7849725484848022,\n",
       "     0.6732819080352783],\n",
       "    [0.731630265712738,\n",
       "     0.22664277255535126,\n",
       "     0.8042165040969849,\n",
       "     0.7227916717529297],\n",
       "    [0.7051327228546143,\n",
       "     0.0027857304085046053,\n",
       "     0.9923284649848938,\n",
       "     0.38319018483161926],\n",
       "    [0.7333341836929321,\n",
       "     0.011372491717338562,\n",
       "     0.7887970209121704,\n",
       "     0.037465114146471024],\n",
       "    [0.7601996064186096,\n",
       "     0.6724775433540344,\n",
       "     0.7893114686012268,\n",
       "     0.7148659825325012],\n",
       "    [0.7264726758003235,\n",
       "     0.2697400748729706,\n",
       "     0.7960957884788513,\n",
       "     0.3202621340751648],\n",
       "    [0.7608110904693604,\n",
       "     0.434408038854599,\n",
       "     0.7846875786781311,\n",
       "     0.4606602191925049],\n",
       "    [0.41711369156837463,\n",
       "     0.1574379950761795,\n",
       "     0.8703448176383972,\n",
       "     0.955699622631073],\n",
       "    [0.7640566229820251,\n",
       "     0.6577333211898804,\n",
       "     0.7849725484848022,\n",
       "     0.6732819080352783],\n",
       "    [0.7651740908622742,\n",
       "     0.6742131114006042,\n",
       "     0.7901628017425537,\n",
       "     0.7028006911277771],\n",
       "    [0.7563371062278748,\n",
       "     0.6796043515205383,\n",
       "     0.7901085615158081,\n",
       "     0.7182846069335938],\n",
       "    [0.6318125128746033,\n",
       "     0.6345821022987366,\n",
       "     0.6767342686653137,\n",
       "     0.681001603603363],\n",
       "    [0.7401124835014343,\n",
       "     0.5224645137786865,\n",
       "     0.7744139432907104,\n",
       "     0.5671128630638123],\n",
       "    [0.44594961404800415,\n",
       "     0.7825868725776672,\n",
       "     0.48218274116516113,\n",
       "     0.8035241365432739],\n",
       "    [0.44688698649406433,\n",
       "     0.7824220061302185,\n",
       "     0.47040191292762756,\n",
       "     0.8002155423164368],\n",
       "    [0.6320257186889648,\n",
       "     0.0007321119192056358,\n",
       "     0.817933976650238,\n",
       "     0.7030057311058044],\n",
       "    [0.6370648145675659,\n",
       "     0.0004547789867501706,\n",
       "     0.8446032404899597,\n",
       "     0.04562247917056084],\n",
       "    [0.7634189128875732,\n",
       "     0.6756885051727295,\n",
       "     0.7859651446342468,\n",
       "     0.6952807307243347],\n",
       "    [0.7250673770904541,\n",
       "     0.006417641881853342,\n",
       "     0.7749567627906799,\n",
       "     0.0208726953715086]]]},\n",
       " 'detection_scores': {'shape': [1, 100],\n",
       "  'value': [[0.9232863783836365,\n",
       "    0.9062605500221252,\n",
       "    0.8349295258522034,\n",
       "    0.7464649081230164,\n",
       "    0.6605350971221924,\n",
       "    0.621105432510376,\n",
       "    0.35884737968444824,\n",
       "    0.26110389828681946,\n",
       "    0.25948935747146606,\n",
       "    0.21697749197483063,\n",
       "    0.2148900181055069,\n",
       "    0.2089657038450241,\n",
       "    0.12803012132644653,\n",
       "    0.12533462047576904,\n",
       "    0.11462974548339844,\n",
       "    0.08809400349855423,\n",
       "    0.08376789093017578,\n",
       "    0.08022992312908173,\n",
       "    0.07390788942575455,\n",
       "    0.06919560581445694,\n",
       "    0.06671907752752304,\n",
       "    0.059375278651714325,\n",
       "    0.05819651857018471,\n",
       "    0.042411383241415024,\n",
       "    0.04138565808534622,\n",
       "    0.03616371005773544,\n",
       "    0.03536975756287575,\n",
       "    0.034987058490514755,\n",
       "    0.030914826318621635,\n",
       "    0.028797615319490433,\n",
       "    0.027747925370931625,\n",
       "    0.026488056406378746,\n",
       "    0.024819299578666687,\n",
       "    0.024645842611789703,\n",
       "    0.0223886426538229,\n",
       "    0.0214508306235075,\n",
       "    0.0195703636854887,\n",
       "    0.017968760803341866,\n",
       "    0.017722945660352707,\n",
       "    0.015665220096707344,\n",
       "    0.014738082885742188,\n",
       "    0.01417763065546751,\n",
       "    0.014155532233417034,\n",
       "    0.014116103760898113,\n",
       "    0.01405481155961752,\n",
       "    0.01353914849460125,\n",
       "    0.013453074730932713,\n",
       "    0.012928484939038754,\n",
       "    0.012608559802174568,\n",
       "    0.01212761364877224,\n",
       "    0.011922460049390793,\n",
       "    0.01086682640016079,\n",
       "    0.009866109117865562,\n",
       "    0.009608658030629158,\n",
       "    0.009444326162338257,\n",
       "    0.009319349192082882,\n",
       "    0.008804960176348686,\n",
       "    0.008727481588721275,\n",
       "    0.008719668723642826,\n",
       "    0.00865738745778799,\n",
       "    0.00830128788948059,\n",
       "    0.007988469675183296,\n",
       "    0.007400617469102144,\n",
       "    0.007043216377496719,\n",
       "    0.007019825279712677,\n",
       "    0.006969710346311331,\n",
       "    0.006900775246322155,\n",
       "    0.0067516821436584,\n",
       "    0.006391484290361404,\n",
       "    0.006266240496188402,\n",
       "    0.006108598783612251,\n",
       "    0.0060417912900447845,\n",
       "    0.005878261756151915,\n",
       "    0.005835423246026039,\n",
       "    0.005696798209100962,\n",
       "    0.005470497068017721,\n",
       "    0.005143459886312485,\n",
       "    0.005097877234220505,\n",
       "    0.004930359777063131,\n",
       "    0.004900916945189238,\n",
       "    0.004719436634331942,\n",
       "    0.004615998361259699,\n",
       "    0.004313847981393337,\n",
       "    0.0041870297864079475,\n",
       "    0.0040711103938519955,\n",
       "    0.003910757135599852,\n",
       "    0.003890614490956068,\n",
       "    0.0038794628344476223,\n",
       "    0.0037565960083156824,\n",
       "    0.0034155291505157948,\n",
       "    0.0034098962787538767,\n",
       "    0.0033458999823778868,\n",
       "    0.0033029604237526655,\n",
       "    0.0029701082967221737,\n",
       "    0.002951448317617178,\n",
       "    0.002936192322522402,\n",
       "    0.0028608660213649273,\n",
       "    0.002837193664163351,\n",
       "    0.002766614081338048,\n",
       "    0.002683148719370365]]}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector_result_score1['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.convert_to_tensor(np.array(detector_result_score1['1']['detection_classes']['value']))\n",
    "\n",
    "file_paths = [\"detector_result_score\"+str(i)+\".json\" for i in range(1, 5)]\n",
    "file_jsons = {}\n",
    "for i in range(0,4):\n",
    "    file_path = file_paths[i]\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_jsons[str(i)] = json.load(file)\n",
    "\n",
    "file_path = 'detector_result_score_merged.json'\n",
    "\n",
    "# Saving the dictionary to a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(file_jsons, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_paths = [\"detector_result_score_merged.json\", \"detector_result_score_merged2.json\"]\n",
    "file_jsons = {}\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_jsons.update(json.load(file))\n",
    "\n",
    "file_path = 'detector_result_score_merged_final.json'\n",
    "\n",
    "# Saving the dictionary to a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(file_jsons, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_paths = [\"detector_result_score_extra_\"+str(i)+\".json\" for i in range(1, 4)]\n",
    "file_jsons = None\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_json = json.load(file)\n",
    "        if file_jsons is None:\n",
    "            file_jsons = file_json\n",
    "        else:\n",
    "            for i in range(4, 7):\n",
    "                file_jsons[str(i)].update(file_json[str(i)])\n",
    "\n",
    "file_path = 'detector_result_score_merged2.json'\n",
    "\n",
    "# Saving the dictionary to a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(file_jsons, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = 'detector_result_score_merged_final.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    file_jsons = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995840191841125\n",
      "0.5798070430755615\n",
      "0.9975948929786682\n",
      "0.5478035807609558\n",
      "0.9971489310264587\n",
      "0.5973495244979858\n",
      "0.9974767565727234\n"
     ]
    }
   ],
   "source": [
    "file_jsons.keys()\n",
    "for i in range(0, 7):\n",
    "    print(file_jsons[str(i)]['0']['detection_scores']['value'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detector_outputs = []\n",
    "for i in range(0, 5766):\n",
    "    outputs = []\n",
    "    for j in range(0, len(file_jsons)):\n",
    "        detection_classes = tf.convert_to_tensor(np.array(file_jsons[str(j)][str(i)]['detection_classes']['value']))\n",
    "        detection_scores = tf.convert_to_tensor(np.array(file_jsons[str(j)][str(i)]['detection_scores']['value']))\n",
    "        outputs.append((detection_classes, detection_scores))\n",
    "    detector_outputs.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(detector_outputs))\n",
    "print(len(detector_outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.mscoco import load_class_map\n",
    "class_map = load_class_map()\n",
    "\n",
    "signals = ['traffic light', 'stop sign']\n",
    "vehicles = ['car', 'bus', 'truck', 'train', 'motorcycle', 'bicycle', 'airplane', 'boat']\n",
    "confidence_score_threshold = 0.43 # 0.42 using the first 4 detectors\n",
    "\n",
    "score_pred = []\n",
    "\n",
    "for i in range(0, 5766):\n",
    "    model_outputs = detector_outputs[i]\n",
    "    image_pred = []\n",
    "    \n",
    "    for j in range(0, 7):\n",
    "        detection_classes, detection_scores = model_outputs[j]\n",
    "        classes_np = detection_classes[0].numpy()\n",
    "        scores_np = detection_scores[0].numpy()\n",
    "\n",
    "        # Store the scores > threshold\n",
    "        scores_g50_indices = np.where(scores_np > confidence_score_threshold)\n",
    "        scores_g50 = scores_np[scores_g50_indices]\n",
    "        \n",
    "        # Store the classes with scores > threshold\n",
    "        classes_g50 = classes_np[scores_g50_indices]\n",
    "        \n",
    "        # Turn the classes into labels\n",
    "        class_labels = class_map.loc[classes_g50].reset_index(drop=True)\n",
    "        class_scores = pd.Series(scores_g50).rename('score')\n",
    "        \n",
    "        class_predictions = pd.concat([class_labels, class_scores], axis=1)\n",
    "        class_predictions = class_predictions.sort_values('score', ascending=False)\n",
    "        class_labels_pred = class_predictions['label'].value_counts()\n",
    "        \n",
    "        # Check if the classes are in the vehicles or signal labels, and keep counts\n",
    "        veh_ct = class_labels_pred.loc[(class_labels_pred.index.isin(vehicles))].sum()\n",
    "        sig_ct = class_labels_pred.loc[(class_labels_pred.index.isin(signals))].sum()\n",
    "        image_pred.append([veh_ct, sig_ct])\n",
    "        \n",
    "        # Get the maximum across the models\n",
    "        max_veh_ct = max(m[0] for m in image_pred)\n",
    "        max_sig_ct = max(m[1] for m in image_pred)\n",
    "    \n",
    "    # print(image_pred)\n",
    "    score_pred.append([max_veh_ct, max_sig_ct])\n",
    "    # print(score_pred)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766\n"
     ]
    }
   ],
   "source": [
    "print(len(score_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal</th>\n",
       "      <th>vehicle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   signal  vehicle\n",
       "0       0        2\n",
       "1       0        0\n",
       "2       0        1\n",
       "3       0        1\n",
       "4       0        1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_y_hat = pd.DataFrame(score_pred, columns=['vehicle', 'signal'])\n",
    "score_y_hat = score_y_hat[['signal','vehicle']]\n",
    "score_y_hat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your predictions on the Score segment as a Pandas data frame into a variable named `score_y_hat`.\n",
    "# The data frame should contain 2 columns: signal and vehicle.\n",
    "\n",
    "# Use the following asserts to check the type and shape of the final predictions.\n",
    "assert type(score_y_hat) == pd.DataFrame\n",
    "assert score_y_hat.shape == (score_metadata.shape[0], 2)\n",
    "assert (score_y_hat.columns == ['signal', 'vehicle']).all()\n",
    "\n",
    "# Use the following code to save the final predictions.\n",
    "import os \n",
    "model_dir = 'carnet_model'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "score_y_hat.to_parquet(f'{model_dir}/score_y_hat.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EOF"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "lcc_arn": "arn:aws:sagemaker:us-west-2:081606037347:studio-lifecycle-config/collegium-kernel-r4"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
